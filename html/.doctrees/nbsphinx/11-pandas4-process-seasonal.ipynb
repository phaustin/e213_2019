{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Learning-objectives\" data-toc-modified-id=\"Learning-objectives-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Learning objectives</a></span></li><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#The-context-module-(repeated-from-10-pandas1)\" data-toc-modified-id=\"The-context-module-(repeated-from-10-pandas1)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>The context module (repeated from 10-pandas1)</a></span></li><li><span><a href=\"#Reading-the-processed-data\" data-toc-modified-id=\"Reading-the-processed-data-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Reading the processed data</a></span></li><li><span><a href=\"#Metadata-is-data-about-data\" data-toc-modified-id=\"Metadata-is-data-about-data-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Metadata is data about data</a></span></li><li><span><a href=\"#Read-weather_YVR.csv-into-a-dataframe\" data-toc-modified-id=\"Read-weather_YVR.csv-into-a-dataframe-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Read weather_YVR.csv into a dataframe</a></span><ul class=\"toc-item\"><li><span><a href=\"#Handling-missing-data\" data-toc-modified-id=\"Handling-missing-data-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Handling missing data</a></span></li></ul></li><li><span><a href=\"#Use-apply-to-tag-the-29,190-days-with-their-season\" data-toc-modified-id=\"Use-apply-to-tag-the-29,190-days-with-their-season-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Use apply to tag the 29,190 days with their season</a></span><ul class=\"toc-item\"><li><span><a href=\"#creating-a-new-column-with-apply\" data-toc-modified-id=\"creating-a-new-column-with-apply-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>creating a new column with apply</a></span></li></ul></li><li><span><a href=\"#Grouping-the-data-by-season\" data-toc-modified-id=\"Grouping-the-data-by-season-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Grouping the data by season</a></span><ul class=\"toc-item\"><li><span><a href=\"#Use-a-dictionary-comprehension-put-the-dataframes-into-a-dictionary\" data-toc-modified-id=\"Use-a-dictionary-comprehension-put-the-dataframes-into-a-dictionary-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>Use a dictionary comprehension put the dataframes into a dictionary</a></span></li></ul></li><li><span><a href=\"#Fitting-the-distributions\" data-toc-modified-id=\"Fitting-the-distributions-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Fitting the distributions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Daily-average-temperature\" data-toc-modified-id=\"Daily-average-temperature-9.1\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>Daily average temperature</a></span></li><li><span><a href=\"#Daily-average-total-precipitation\" data-toc-modified-id=\"Daily-average-total-precipitation-9.2\"><span class=\"toc-item-num\">9.2&nbsp;&nbsp;</span>Daily average total precipitation</a></span></li></ul></li><li><span><a href=\"#Saving-the-fit-parameters\" data-toc-modified-id=\"Saving-the-fit-parameters-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Saving the fit parameters</a></span></li><li><span><a href=\"#Grouping-by-decade\" data-toc-modified-id=\"Grouping-by-decade-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Grouping by decade</a></span></li><li><span><a href=\"#Finding-the-median-temperature\" data-toc-modified-id=\"Finding-the-median-temperature-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Finding the median temperature</a></span></li><li><span><a href=\"#Assignment\" data-toc-modified-id=\"Assignment-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>Assignment</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Analyzing precip and temperature data\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "1. Document your project data by capturing important information\n",
    "   as metadata in a json file\n",
    "\n",
    "1. Use the groupby method for a pandas dataframe to group observations\n",
    "   by season\n",
    "\n",
    "1. Find the probability density function (histogram) of temperature and\n",
    "   precipitation data and determine possible statistical models (normal distribution,\n",
    "   exponential distribution) that best describe the variation in the data\n",
    "\n",
    "1. Find best fit parameters for statistical models that describe the precipitation\n",
    "   and temperature data, assuming that temperature and precipitation are\n",
    "   independent of each other.\n",
    "\n",
    "1. Use groupby to find the median temperature for each decade and each season\n",
    "   and determine whether the seasonal temperatures have increased at YVR\n",
    "   since the 1930's\n",
    "\n",
    "## Introduction\n",
    "\n",
    "We have about 30,000 days worth of YVR precipitation and temperature\n",
    "data generated by the 10-pandas1, 10-pandas2, and 10-pandas3 notebooks, these\n",
    "gave you a new csv file: data/processed/weather_YVR.csv.  We will use\n",
    "that data set to estimate statistical distributions that could produce realistic\n",
    "simulated rainfall and temperature inputs to a model.  It makes use of several\n",
    "new python modules/methods:\n",
    "\n",
    "1. The **context** module: We will write a new module called context.py that\n",
    "   will be used to locate folders and libraries associated with a project, such as\n",
    "   `weather_YVR.csv`.\n",
    "1. **The json module**.  This reads and writes files written\n",
    "   in \"javascript object notation\" i.e.\n",
    "   [json](https://en.wikipedia.org/wiki/JSON).  We will use it to\n",
    "   save \"metadata\" or data about our data.\n",
    "\n",
    "1. **pandas.DataFrame.groupby**\n",
    "   We will use groupby to split the dataframe into 4 seasons, each corresponding\n",
    "   to 3 months of the year: winter (month initials djf), spring (mam),\n",
    "   summer (jja), and fall (son).  This is the tip of the iceberg of what\n",
    "   you can do with pandas split/apply/combine functions.  For more examples\n",
    "   see [the Python Data Science Handbook](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.08-Aggregation-and-Grouping.ipynb)\n",
    "\n",
    "1. The [scipy.stats](https://docs.scipy.org/doc/scipy/reference/stats.html) module.  As you will see\n",
    "   below, the temperature data is best fit with a a Gaussian (normal) distribution\n",
    "   using the norm.fit:\n",
    "   - [scipy.stats.norm.fit](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html#scipy.stats.norm)\n",
    "\n",
    "   Precipitation, on the other hand, follows an exponential distribution, which\n",
    "   can be fit with:\n",
    "   - [scipy.stats.expon.fit](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.expon.html#scipy.stats.expon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import context\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "from matplotlib import pyplot as plt\n",
    "import pprint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## The context module (repeated from 10-pandas1)\n",
    "\n",
    "As your project grows more complicated, it's good to have a central\n",
    "module that keeps track of important files and sets your scripts\n",
    "up so that they can import functions and classes from you modules.\n",
    "If you were planning to distribute your project using conda, then\n",
    "you would need to write an installation script, which is a fair\n",
    "amount of work.   At this stage, it's easier and more flexible to\n",
    "store that information in a file that travels along with your notebook.\n",
    "By convention, this file is called:\n",
    "[context.py](https://github.com/phaustin/eosc213_students/blob/master/notebooks/pandas/context.py)\n",
    "\n",
    "Clicking on that link shows you the source -- the code is executed when\n",
    "you do `import context` and does the following:\n",
    "\n",
    "1. Defines Path objects that give the location of the raw and processed data folders\n",
    "\n",
    "1. Puts the notebooks/pandas folder on python's list of places to look for\n",
    "   library modules (sys.path).  We will use this when we start extracting\n",
    "   code from notebooks into libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Here is the path to the processed csv file\n",
    "#\n",
    "print(context.processed_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the processed data\n",
    "\n",
    "The next cell uses [\"globbing\"](https://en.wikipedia.org/wiki/Glob_(programming)) to\n",
    "find every csv file in all folders below `data/processed`.  (See\n",
    "[this optional tutorial](https://realpython.com/python-pathlib/) for more information)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yvr_files = list(context.processed_dir.glob(\"**/*YVR*csv\"))\n",
    "print(f\"yvr files: \\n{pprint.pformat(yvr_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yvr_file = context.processed_dir / \"weather_YVR.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata is data about data\n",
    "\n",
    "Since we care about this dataset, it's a good idea to save\n",
    "details for future reference.  We can't put this kind of information\n",
    "into a csv file, but there are many file formats that can store\n",
    "this type of descriptive metadata -- one of the most popular is\n",
    "[json](https://en.wikipedia.org/wiki/JSON).  In the next cell we\n",
    "write the data into a nested dictionary called meta_dict, and\n",
    "dump that information into a new json file called metadata.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = dict()\n",
    "\n",
    "file_info = dict()\n",
    "file_info[\"written_by\"] = \"10-pandas3-process-daily-data.ipynb\"\n",
    "file_info[\"contact\"] = \"paustin@eoas.ubc.ca\"\n",
    "file_info[\n",
    "    \"description\"\n",
    "] = \"EC canada YVR data downloaded by 10-pandas2-download-daily-data.ipynb\"\n",
    "\n",
    "meta_data[\"weather_daily_YVR_1938-2017_all.csv\"] = file_info\n",
    "\n",
    "file_info = dict()\n",
    "file_info[\"written_by\"] = \"10-pandas3-process-daily-data.ipynb\"\n",
    "file_info[\"contact\"] = \"paustin@eoas.ubc.ca\"\n",
    "file_info[\n",
    "    \"description\"\n",
    "] = \"Reduced YVR data subsetted by 10-pandas3-process-daily-data.ipynb\"\n",
    "\n",
    "meta_data[\"weather_YVR.csv\"] = file_info\n",
    "\n",
    "history_file = context.processed_dir / \"history_metadata.json\"\n",
    "with open(history_file, \"w\") as f:\n",
    "    json.dump(meta_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a minute and look at history_metadata.json with jupyter to see how the metadata is written out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read weather_YVR.csv into a dataframe\n",
    "\n",
    "Here's the dataframe produced by 10-pandas3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yvr_df = pd.read_csv(yvr_file)\n",
    "print(f\"there are {len(yvr_df)} days in the dataframe\")\n",
    "yvr_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling missing data\n",
    "\n",
    "What should we do about missing vlaues like the Rain and Snow totals for Jan./Feb. 1938?\n",
    "This is a judgement call -- we could through away the whole row, or do something\n",
    "more complicated like masking the missing values in calculations where they are referenced.\n",
    "For this notebook we'll fill the NaNs with zeros -- not a great idea since 0 is an\n",
    "actual temperature, but we can see if that makes a difference later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yvr_df.fillna(0.,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use apply to tag the 29,190 days with their season\n",
    "\n",
    "We know that the seasons are quite different, and if we are interested in\n",
    "generating daily data we have to take that into account.  In the next cell\n",
    "we set up a lookup table (dictionary) called season_table that maps the\n",
    "month number to one of four seasons.  With this table we can write\n",
    "a function called find_season that takes a row of the dataframe and\n",
    "returns the season for that row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_table = dict()\n",
    "for i in range(12):\n",
    "    m = i + 1\n",
    "    if m in [12, 1, 2]:\n",
    "        # winter\n",
    "        season_table[m] = \"djf\"\n",
    "    elif m in [3, 4, 5]:\n",
    "        # spring\n",
    "        season_table[m] = \"mam\"\n",
    "    elif m in [6, 7, 8]:\n",
    "        # summer\n",
    "        season_table[m] = \"jja\"\n",
    "    else:\n",
    "        # fall\n",
    "        season_table[m] = \"son\"\n",
    "\n",
    "\n",
    "def find_season(row, season_table):\n",
    "    month = row[\"Month\"]\n",
    "    return season_table[month]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating a new column with apply\n",
    "\n",
    "One of the most useful pandas dataframe methods is [apply](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html).  This method has lots of bells and whistles, all we need here is to apply the `find_season` function to every\n",
    "row of the dataframe, which means that we want to return a new column with the same number of rows\n",
    "as the other columns.  We do that by tell apply that we want to return `axis=1`  (rows are axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season = yvr_df.apply(find_season, args=(season_table,), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now add that column to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yvr_df[\"season\"] = season\n",
    "yvr_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping the data by season\n",
    "\n",
    "The next cell uses the groupby method to sort all of the\n",
    "rows into 4 seasons.  The resulting group object (`seasons`) has\n",
    "4 dataframes inside it, keyed by the season marker djf, mam, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = yvr_df.groupby(\"season\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# this creates a new object of type DataFrameGroupBy\n",
    "#\n",
    "print(type(seasons))\n",
    "seasons.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a dictionary comprehension put the dataframes into a dictionary\n",
    "\n",
    "In the next cell we create a new dictionary by iterating over the DataFrameGroupBy object.  We\n",
    "will use a [dictionary comprehension](https://jakevdp.github.io/WhirlwindTourOfPython/11-list-comprehensions.html),\n",
    "to simplify the loop -- note that we wind up with 4 dataframes in the dictionary,\n",
    "one for each season.  We do this because a dictionary of dataframes is simpler to work with than\n",
    "the DataFrameGroupBy object, which somewhat obscures the season keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_dict = {key: value for key, value in seasons}\n",
    "season_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how you get the fall (son) dataframe from the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_dict[\"son\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the distributions\n",
    "\n",
    "What does it mean to \"fit\" a distribution?  We want to be able to generate a series of random\n",
    "numbers that resemble temperatures and precip amounts that we might see at YVR during a \n",
    "particular season.  We need to find two things:\n",
    "\n",
    "1. A probability density function (pdf) that has a similar shape to the histogram\n",
    "   we get from the data.\n",
    "   \n",
    "1. The best choice of parameters for that pdf that getting it \"closest\" in some statistical\n",
    "   sense to the data.\n",
    "   \n",
    "You'll see below that temperature is best fit with a Gaussin (normal) distribution, whilc\n",
    "precipitation more closely follows an exponential distribution.  Both the normal and\n",
    "exponential distributions are functions of two parameters.  For the normal distribution,\n",
    "the best estimate (maximum likelihood values) of those parameters is provided by the \n",
    "mean and the standard deviation of the temperature data.  For the exponential distribution,\n",
    "they are given by the minimum value and the mean.\n",
    "\n",
    "### Daily average temperature\n",
    "\n",
    "The next cell shows histograms temperature for each of the seasons.  We use\n",
    "[scipy.stats.norm.fit](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html#scipy.stats.norm) to\n",
    "find the mean and standard deviation (called the `loc` and `scale` here) of the data\n",
    "and then shows that fitted distribution as a red line.  Specifically, for temperatures x the red\n",
    "line is a plot of:\n",
    "\n",
    "\\begin{align*}\n",
    "f(y) &= \\frac{\\exp(-y^2/2)}{\\sqrt{2\\pi}} \\\\\n",
    "y &= (x - loc) / scale\n",
    "\\end{align*}\n",
    "\n",
    "The four plots show that a normal distribution give as pretty good representation of each of the seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "key_list = [\"djf\", \"mam\", \"jja\", \"son\"]\n",
    "df_list = [season_dict[key] for key in key_list]\n",
    "#\n",
    "# set up a 2 row, 2 column grid of figures, and\n",
    "# turn the ax_array 2-d array into a list\n",
    "#\n",
    "fig, ax_array = plt.subplots(2, 2, figsize=(8, 8))\n",
    "ax_list = ax_array.flatten()\n",
    "#\n",
    "# here is the variable we want to histogram\n",
    "#\n",
    "var = \"T_mean (C)\"\n",
    "#\n",
    "# store the fit parameters in a dictionary\n",
    "# called temp_params for future reference\n",
    "#\n",
    "temp_params = dict()\n",
    "#\n",
    "#  loop over the four seasons in key_list\n",
    "#  getting the figure axis and the dataframe\n",
    "#  for that season.  \n",
    "#\n",
    "for index, key in enumerate(key_list):\n",
    "    the_ax = ax_list[index]\n",
    "    the_df = df_list[index]\n",
    "    the_temps = the_df[var]\n",
    "    #\n",
    "    # find the mean and standard deviation to\n",
    "    # set the pdf mu, sigma parameters\n",
    "    #\n",
    "    mu, sigma = st.norm.fit(the_temps)\n",
    "    #\n",
    "    # save the parameter pair for that season\n",
    "    #\n",
    "    temp_params[key] = (mu, sigma)\n",
    "    #\n",
    "    # get the histogram values, the bin edges and the plotting\n",
    "    # bars (patches) for the histogram, specifying 20 bins\n",
    "    # note that we can specify the histogram variable by it's dataframe\n",
    "    # column name when we pass the dataframe to matplotlib via\n",
    "    # the data keyword\n",
    "    #\n",
    "    vals, bins, patches = the_ax.hist(var, bins=20, data=the_df, density=True)\n",
    "    #\n",
    "    # turn the bin edges into bin centers by averaging the right + left\n",
    "    # edge of every bin\n",
    "    #\n",
    "    bin_centers = (bins[1:] + bins[0:-1]) / 2.0\n",
    "    #\n",
    "    # plot the pdf function on top of the histogram as a red line\n",
    "    #\n",
    "    the_ax.plot(bin_centers, st.norm.pdf(bin_centers, mu, sigma), \"r-\")\n",
    "    the_ax.grid(True)\n",
    "    the_ax.set(title=key)\n",
    "    #\n",
    "    # label the xaxis for the bottom two plots (2 and 3)\n",
    "    # and the yaxis for the left plots (0 and 2)\n",
    "    #\n",
    "    if index > 1:\n",
    "        the_ax.set(xlabel=var)\n",
    "    if index in [0,2]:\n",
    "        the_ax.set(ylabel='relative frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily average total precipitation\n",
    "\n",
    "Precipitation data is a different story.  Because negative precipitation\n",
    "is impossible, there is no way a normal distribution is going to work\n",
    "to represent the variablity.  Instead we use\n",
    "[scipy.stats.expon.fit](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.expon.html#scipy.stats.expon) to fit an exponential distribution.\n",
    "\n",
    "\\begin{align*}\n",
    "f(y) &= \\exp(-y)\\\\\n",
    "y &= (x - loc) / scale\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "where `loc` is the minimum of the data and `scale` is the distance\n",
    "between the minimum and the mean.\n",
    "\n",
    "The fits are not quite as good -- but do capture the one-sided nature\n",
    "of the variability.  No comments on this one, but it's a copy and paste of\n",
    "the temperature grid plot above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_array = plt.subplots(2, 2, figsize=(8, 8))\n",
    "ax_list = ax_array.flatten()\n",
    "var = \"Total Precip (mm)\"\n",
    "precip_params = dict()\n",
    "for index, key in enumerate(key_list):\n",
    "    the_ax = ax_list[index]\n",
    "    the_df = df_list[index]\n",
    "    the_precip = the_df[var]\n",
    "    loc, scale = st.expon.fit(the_precip)\n",
    "    precip_params[key] = (loc, scale)\n",
    "    vals, bins, patches = the_ax.hist(var, bins=20, data=the_df, density=True)\n",
    "    bin_centers = (bins[1:] + bins[0:-1]) / 2.0\n",
    "    the_ax.plot(bin_centers, st.expon.pdf(bin_centers, loc, scale), \"r-\")\n",
    "    the_ax.grid(True)\n",
    "    the_ax.set(title=key)\n",
    "    #\n",
    "    # label the xaxis for the bottom two plots (2 and 3)\n",
    "    # and the yaxis for the left plots (0 and 2)\n",
    "    #\n",
    "    if index > 1:\n",
    "        the_ax.set(xlabel=var)\n",
    "    if index in [0,2]:\n",
    "        the_ax.set(ylabel='relative frequency')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the fit parameters\n",
    "\n",
    "We have two new dictionaries: `temp_params` and `precip_params` that\n",
    "we should save for the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = dict()\n",
    "data_dict[\n",
    "    \"metadata\"\n",
    "] = \"\"\"\n",
    "          loc,scale tuples for daily average temperature (deg C)\n",
    "          and precipitation (mm) produced by 11-pandas4 for YVR\n",
    "          \"\"\"\n",
    "data_dict[\"temp\"] = temp_params\n",
    "data_dict[\"precip\"] = precip_params\n",
    "fit_file = context.processed_dir / \"fit_metadata.json\"\n",
    "with open(fit_file, \"w\") as f:\n",
    "    json.dump(data_dict, f, indent=4)\n",
    "    \n",
    "print(f\"wrote the fit coefficients to {fit_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# here's what the file looks like:\n",
    "#\n",
    "\n",
    "with open(fit_file,'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping by decade\n",
    "\n",
    "The two functions below take a season dataframe and\n",
    "create a new column with the decade that each day belongs\n",
    "to.  For example if a measurement in taken in 1941, then\n",
    "its decade is 194.  We can use that see whether the temperature\n",
    "at the airport has been increasing since the 1930's and whether\n",
    "that increase depends on season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_decade(row):\n",
    "    \"\"\"\n",
    "    given a row from an Environment Canada dataframe\n",
    "    return the first 3 digits of the year as an integer\n",
    "    \n",
    "    i.e. turn \"2010\" into the number 201\n",
    "    \"\"\"\n",
    "    year_string=f\"{row['Year']:4d}\"\n",
    "    return int(year_string[:3])\n",
    "\n",
    "\n",
    "def decadal_groups(season_df):\n",
    "    \"\"\"\n",
    "    given a season dataframe produced by groupby('season'), add\n",
    "    a column called 'decade' with the 3 digit decade\n",
    "    and return a groupby dictionary of decade dataframes for that\n",
    "    season with the decade as key\n",
    "    \"\"\"\n",
    "    #\n",
    "    # add the decade column to the dataframe using apply\n",
    "    #\n",
    "    decade=season_df.apply(find_decade,axis=1)\n",
    "    season_df['decade']=decade\n",
    "    #\n",
    "    # do the groupby and turn into a dictionary\n",
    "    #\n",
    "    decade_groups=season_df.groupby('decade')\n",
    "    decade_dict={key:value for key,value in decade_groups}\n",
    "    return decade_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the median temperature\n",
    "\n",
    "Once we have the dictionary that has the decade as key and\n",
    "the dataframe for that decade as value, we can find the median\n",
    "value of the daily average temperature for each decade using\n",
    "the `median_temps` function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_temps(decade_dict):\n",
    "    \"\"\"\n",
    "    given a decade_dict produced by the decadal_temp function\n",
    "    return a 2-column numpy array.  The first column should be the\n",
    "    integer decade (193,194,etc.) and the second column should be\n",
    "    the median temperature for that decade\n",
    "    \"\"\"\n",
    "    values=list()\n",
    "    for the_decade,the_df in decade_dict.items():\n",
    "        T_median=the_df['T_mean (C)'].median()\n",
    "        values.append((the_decade,T_median))\n",
    "    result=np.array(values)\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "\n",
    "Using the functions above, calculate the median temperature for\n",
    "each decade and save your (decade, temperature) lists into\n",
    "a dictionary with a key for each season.  Use that dictionary\n",
    "to make a 2 x 2 plot of temperature vs. decade for each of the\n",
    "four seasons, using the 4 box plotting code above.  (My solution\n",
    "is 14 lines long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d937e270e59de55d9c0874ef073b9db7",
     "grade": true,
     "grade_id": "cell-55c843e9a4c0efe7",
     "locked": false,
     "points": 10,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all",
   "notebook_metadata_filter": "all,-language_info",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.2",
    "jupytext_version": "1.0.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "nbsphinx": {
   "execute": "never"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
